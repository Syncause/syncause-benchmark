"""
SREChat RCAç®—æ³•
è¿™æ˜¯ä¸€ç§åŸºäºè¿œç¨‹APIè°ƒç”¨å’Œå¤§æ¨¡å‹è§£æçš„RCAç®—æ³•
åªéœ€è¦æä¾›æ£€æµ‹æ—¶é—´ï¼Œç®—æ³•ä¼šè‡ªå·±è·å–æ•°æ®å¹¶è¿”å›æ ¹å› 
"""

import os
import json
import requests
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Any
import warnings

warnings.filterwarnings("ignore")


def _infer_reason_suffix(report_text: str, service_name: str) -> str:
    """Infer a short reason suffix (e.g., cpu/mem/latency/disk/loss/socket) for a given service
    based on keywords in the report text around global context.

    The fallback is 'latency' to align with README examples.
    """
    text = (report_text or "").lower()

    # Common categories observed across the project
    # Prioritize more specific signals first
    if "memory" in text or "mem" in text:
        return "mem"
    if "cpu" in text or "runq" in text or "epoll" in text:
        return "cpu"
    if "disk" in text or "i/o" in text or "io " in text or "file i/o" in text:
        return "disk"
    if "packet loss" in text or "loss" in text:
        return "loss"
    if "socket" in text:
        return "socket"
    if "network" in text or "rtt" in text or "bandwidth" in text:
        # Some baselines use 'socket', but many examples show 'latency'
        # Prefer 'latency' unless socket explicitly appears
        return "latency"
    if "slow" in text or "delay" in text or "latency" in text or "response time" in text:
        return "latency"
    # Default fallback
    return "latency"


def _format_service_reasons(services: List[str], report_text: str) -> List[str]:
    formatted: List[str] = []
    seen = set()
    for svc in services:
        base = str(svc)
        if base in seen:
            continue
        seen.add(base)
        suffix = _infer_reason_suffix(report_text, base)
        formatted.append(f"{base}_{suffix}")
    return formatted


def _extract_rca_from_report(report_text: str) -> Dict[str, Any]:
    """Extract RCA summary, detailed report markdown, and services from the RCA table
    that was embedded into report_text when the stream contained AgentToolDisplay.

    Return keys:
      - rca_summary: Optional[str]
      - rca_report_markdown: Optional[str]
      - rca_services_from_table: List[str]
    """
    summary = None
    detailed = None
    services: List[str] = []
    if not report_text:
        return {
            "rca_summary": summary,
            "rca_report_markdown": detailed,
            "rca_services_from_table": services,
        }

    text = report_text
    # Try to extract the block we inserted
    # SUMMARY:
    if "SUMMARY:" in text:
        start = text.find("SUMMARY:") + len("SUMMARY:")
        # end before DETAILED REPORT or Original Response divider
        end = text.find("\n\nDETAILED REPORT:", start)
        if end == -1:
            end = text.find("\n\n===", start)
        if end == -1:
            end = start + 2000
        summary = text[start:end].strip()

    # DETAILED REPORT:
    if "DETAILED REPORT:" in text:
        dstart = text.find("DETAILED REPORT:") + len("DETAILED REPORT:")
        dend = text.find("\n\n===", dstart)
        if dend == -1:
            dend = dstart + 20000
        detailed = text[dstart:dend].strip()

    # Extract services from the markdown table (| ts-...service | ... |)
    lines = text.splitlines()
    for ln in lines:
        ln_stripped = ln.strip()
        if ln_stripped.startswith("|") and "service" in ln_stripped.lower():
            # header line, skip
            continue
        if ln_stripped.startswith("|") and ("ts-" in ln_stripped or "service" in ln_stripped.lower()):
            # try to capture the first cell as service name
            try:
                cells = [c.strip() for c in ln_stripped.strip('|').split('|')]
                if cells:
                    candidate = cells[0]
                    # backticks or plain
                    candidate = candidate.replace('`', '').strip()
                    # æ›´å®½æ¾çš„åŒ¹é…ï¼šåŒ…å«serviceæˆ–è€…ts-å¼€å¤´
                    if (candidate.endswith("service") or candidate.startswith("ts-")) and candidate not in services:
                        services.append(candidate)
            except Exception:
                pass
    
    # å¦‚æœè¡¨æ ¼è§£æå¤±è´¥ï¼Œå°è¯•æ­£åˆ™è¡¨è¾¾å¼æå–
    if not services:
        import re
        # åŒ¹é… | ts-xxx-service | æ ¼å¼
        table_pattern = r'\|\s*(ts-[a-z0-9-]+service)\s*\|'
        table_matches = re.findall(table_pattern, text, re.IGNORECASE)
        if table_matches:
            for svc in table_matches:
                if svc not in services:
                    services.append(svc)
    
    # å¯é€‰è°ƒè¯•ï¼šæ‰“å°è§£æç»“æœï¼ˆä»…åœ¨verbose=Trueæ—¶ï¼‰
    # if not services and "ts-" in text:
    #     print(f"DEBUG: è¡¨æ ¼è§£æå¤±è´¥ï¼Œæ–‡æœ¬ä¸­åŒ…å«ts-: {text.count('ts-')}æ¬¡")
    # elif services:
    #     print(f"DEBUG: æˆåŠŸè§£æè¡¨æ ¼æœåŠ¡: {services}")

    return {
        "rca_summary": summary,
        "rca_report_markdown": detailed,
        "rca_services_from_table": services,
    }


def parse_report_with_llm(report_text: str, api_key: str = None, model_name: str = None, base_url: str = None, verbose: bool = False) -> List[str]:
    """
    ä½¿ç”¨å¤§æ¨¡å‹è§£ææ ¹å› æŠ¥å‘Šï¼Œæå–top5æ ¹å› 
    æ”¯æŒå¤šç§æ¨¡å‹ï¼šDeepSeekã€Qwen-Plusç­‰
    
    Args:
        report_text: æ ¹å› æŠ¥å‘Šæ–‡æœ¬
        api_key: APIå¯†é’¥
        model_name: æ¨¡å‹åç§° (å¦‚ 'deepseek-chat', 'qwen-plus')
        base_url: APIåŸºç¡€URL
    
    Returns:
        top5æ ¹å› åˆ—è¡¨
    """
    # è¯»å–é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨å‚æ•°ï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡ï¼‰
    if api_key is None:
        api_key = os.getenv("LLM_API_KEY") or os.getenv("DEEPSEEK_API_KEY")
    
    if model_name is None:
        model_name = os.getenv("LLM_MODEL_NAME", "qwen-plus")
    
    if base_url is None:
        base_url = os.getenv("LLM_BASE_URL", "https://dashscope.aliyuncs.com/compatible-mode/v1")
    
    if not api_key:
        if verbose:
            print("è­¦å‘Š: æœªæä¾›LLM_API_KEYï¼Œå°†å°è¯•ç®€å•è§£æ")
        return simple_parse_report(report_text)
    
    try:
        # æ„å»ºAPI URL
        if not base_url.endswith('/'):
            base_url += '/'
        url = base_url + "chat/completions"
        
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ ¹å› æŠ¥å‘Šï¼Œæå–å‡ºæœ€é‡è¦çš„å‰5ä¸ªæ ¹å› æœåŠ¡ã€‚
è¦æ±‚ï¼š
1. åªè¿”å›æœåŠ¡åç§°åˆ—è¡¨ï¼Œæ¯ä¸ªæœåŠ¡ä¸€è¡Œ
2. æŒ‰ç…§é‡è¦æ€§ä»é«˜åˆ°ä½æ’åº
3. ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–é¢å¤–ä¿¡æ¯
4. å¦‚æœæ ¹å› å°‘äº5ä¸ªï¼Œè¿”å›æ‰€æœ‰æ ¹å› 
5. åªè¿”å›æœåŠ¡åç§°ï¼Œå¦‚ï¼šts-order-service

æŠ¥å‘Šå†…å®¹ï¼š
{report_text[:5000]}

è¯·ç›´æ¥è¿”å›æ ¹å› æœåŠ¡åˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªæœåŠ¡åï¼‰ï¼š"""

        payload = {
            "model": model_name,
            "messages": [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç³»ç»Ÿæ ¹å› åˆ†æä¸“å®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            "temperature": 0.3,
            "max_tokens": 500
        }
        
        if verbose:
            print(f"ä½¿ç”¨æ¨¡å‹: {model_name} (URL: {url})")
        response = requests.post(url, headers=headers, json=payload, timeout=30)
        response.raise_for_status()
        
        result = response.json()
        content = result["choices"][0]["message"]["content"].strip()
        
        # è§£æè¿”å›çš„æ ¹å› åˆ—è¡¨
        root_causes = [line.strip() for line in content.split('\n') if line.strip()]
        # ç§»é™¤å¯èƒ½çš„åºå·å‰ç¼€ï¼ˆå¦‚ "1. ", "- " ç­‰ï¼‰
        root_causes = [rc.lstrip('0123456789.-) ').strip() for rc in root_causes]
        # è¿‡æ»¤ç©ºå­—ç¬¦ä¸²å’ŒéæœåŠ¡å
        root_causes = [rc for rc in root_causes if rc and 'service' in rc.lower()]
        
        # ç¡®ä¿æœ€å¤šè¿”å›5ä¸ª
        return root_causes[:5] if root_causes else simple_parse_report(report_text)
        
    except Exception as e:
        print(f"LLM APIè°ƒç”¨å¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•è§£æ")
        return simple_parse_report(report_text)


# ä¿æŒå‘åå…¼å®¹
def parse_report_with_deepseek(report_text: str, api_key: str = None) -> List[str]:
    """
    ä½¿ç”¨DeepSeekå¤§æ¨¡å‹è§£ææ ¹å› æŠ¥å‘Šï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
    ç°åœ¨å®é™…è°ƒç”¨parse_report_with_llm
    """
    return parse_report_with_llm(
        report_text, 
        api_key=api_key,
        model_name="deepseek-chat",
        base_url="https://api.deepseek.com/v1"
    )


def simple_parse_report(report_text: str) -> List[str]:
    """
    ç®€å•çš„æŠ¥å‘Šè§£ææ–¹æ³•ï¼Œå½“æ— æ³•ä½¿ç”¨å¤§æ¨¡å‹æ—¶ä½¿ç”¨
    ä¼˜å…ˆè§£æRoot Cause Analysisè¡¨æ ¼ï¼Œç„¶åå°è¯•æå–æœåŠ¡åç§°
    
    Args:
        report_text: æ ¹å› æŠ¥å‘Šæ–‡æœ¬
    
    Returns:
        æ ¹å› åˆ—è¡¨
    """
    import json
    import re
    
    root_causes = []
    
    # ä¼˜å…ˆçº§1: ä»Root Cause Analysisè¡¨æ ¼ä¸­æå–
    # æŸ¥æ‰¾ç±»ä¼¼ "| ts-order-service | CPU usage spiked..." çš„è¡Œ
    table_pattern = r'\|\s*([a-z0-9-]+service)\s*\|[^|]+\|[^|]*ğŸ”[^|]*\|'
    table_matches = re.findall(table_pattern, report_text, re.IGNORECASE)
    if table_matches:
        for svc in table_matches:
            if svc not in root_causes:
                root_causes.append(svc)
        if len(root_causes) >= 5:
            return root_causes[:5]
    
    # ä¼˜å…ˆçº§2: ä»æ ‡é¢˜æˆ–é‡ç‚¹æ ‡è®°ä¸­æå– (å¦‚ "### ğŸš¨ `ts-order-service`")
    title_pattern = r'###?\s*ğŸš¨\s*`?([a-z0-9-]+service)`?'
    title_matches = re.findall(title_pattern, report_text, re.IGNORECASE)
    if title_matches:
        for svc in title_matches:
            if svc not in root_causes:
                root_causes.append(svc)
        if len(root_causes) >= 5:
            return root_causes[:5]
    
    # ä¼˜å…ˆçº§3: å°è¯•è§£æJSONæ ¼å¼
    json_objects = []
    try:
        # å°è¯•ç›´æ¥è§£ææ•´ä¸ªæ–‡æœ¬
        data = json.loads(report_text)
        json_objects.append(data)
    except (json.JSONDecodeError, ValueError):
        # å°è¯•æå–å¤šä¸ªJSONå¯¹è±¡
        json_pattern = r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}'
        matches = re.findall(json_pattern, report_text)
        for match in matches:
            try:
                obj = json.loads(match)
                if isinstance(obj, dict):
                    json_objects.append(obj)
            except:
                pass
    
    # ä»æ‰€æœ‰JSONå¯¹è±¡ä¸­æå–æ ¹å› 
    for data in json_objects:
        if not isinstance(data, dict):
            continue
            
        # abnormalServices (æ˜ç¡®çš„å¼‚å¸¸æœåŠ¡æ ‡è®°)
        if 'abnormalServices' in data and isinstance(data['abnormalServices'], list):
            for svc in data['abnormalServices']:
                if svc not in root_causes:
                    root_causes.append(svc)
        
        # serviceåˆ—è¡¨
        if 'service' in data and isinstance(data['service'], list):
            for svc in data['service']:
                if svc not in root_causes:
                    root_causes.append(svc)
        
        # å…¶ä»–å¯èƒ½çš„å­—æ®µ
        for key in ['root_causes', 'causes', 'issues', 'problems', 'services']:
            if key in data:
                if isinstance(data[key], list):
                    for item in data[key]:
                        if item not in root_causes:
                            root_causes.append(str(item))
                elif isinstance(data[key], str):
                    if data[key] not in root_causes:
                        root_causes.append(data[key])
    
    if root_causes:
        return root_causes[:5]
    
    # å¦‚æœæ˜¯åˆ—è¡¨æ ¼å¼
    for data in json_objects:
        if isinstance(data, list):
            return [str(item) for item in data[:5]]
    
    # å¸¸è§çš„æ ¹å› å…³é”®è¯
    keywords = [
        "cpu", "memory", "disk", "network", "latency", "timeout",
        "error", "exception", "service", "pod", "container", "node"
    ]
    
    # å°è¯•æå–æœåŠ¡åç§° (å¦‚ ts-xxx-service, xxx-serviceç­‰)
    service_pattern = r'\b([\w-]+service)\b'
    services = re.findall(service_pattern, report_text.lower())
    if services:
        # å»é‡å¹¶è¿”å›å‰5ä¸ª
        unique_services = []
        for svc in services:
            if svc not in unique_services:
                unique_services.append(svc)
            if len(unique_services) >= 5:
                return unique_services[:5]
        if unique_services:
            root_causes.extend(unique_services)
    
    # å°è¯•æå–åŒ…å«å…³é”®è¯çš„è¡Œ
    lines = report_text.split('\n')
    for line in lines:
        line_lower = line.lower()
        for keyword in keywords:
            if keyword in line_lower and line.strip():
                # æ¸…ç†å¹¶æ·»åŠ 
                cleaned = line.strip().lstrip('*-â€¢123456789. ')
                if cleaned and cleaned not in root_causes:
                    root_causes.append(cleaned)
                    if len(root_causes) >= 5:
                        return root_causes[:5]
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„æ ¹å› ï¼Œè¿”å›å‰å‡ è¡Œéç©ºå†…å®¹
    if len(root_causes) < 5:
        for line in lines:
            cleaned = line.strip()
            if cleaned and cleaned not in root_causes:
                root_causes.append(cleaned)
                if len(root_causes) >= 5:
                    break
    
    return root_causes[:5] if root_causes else ["æœªèƒ½è§£æå‡ºæ ¹å› "]


def call_srechat_api(
    detect_time: str,
    api_url: str = "http://120.26.30.82/:31338/api/v1/srechat",
    thread_id: str = None,
    run_id: str = None,
    time_window_minutes: int = 15,
    verbose: bool = False
) -> str:
    """
    è°ƒç”¨SREChat APIè·å–æ ¹å› æŠ¥å‘Š
    
    Args:
        detect_time: æ£€æµ‹æ—¶é—´ï¼Œæ ¼å¼å¦‚ "2025-09-23T17:20:42+08:00"
        api_url: APIåœ°å€
        thread_id: çº¿ç¨‹IDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        run_id: è¿è¡ŒIDï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        time_window_minutes: æ—¶é—´çª—å£ï¼ˆåˆ†é’Ÿï¼‰
    
    Returns:
        æ ¹å› æŠ¥å‘Šæ–‡æœ¬
    """
    import time
    
    # ç”ŸæˆID
    if thread_id is None:
        thread_id = f"thread_{int(time.time() * 1000)}_{os.urandom(4).hex()}"
    if run_id is None:
        run_id = f"run_{int(time.time() * 1000)}_{os.urandom(4).hex()}"
    
    # è®¡ç®—æ—¶é—´èŒƒå›´
    from datetime import datetime, timedelta
    
    # è§£æ detect_time (æ ¼å¼: "2025-10-21T19:40:13+08:00")
    if detect_time.endswith('+08:00'):
        dt_str = detect_time[:-6]  # ç§»é™¤ "+08:00"
        detect_dt = datetime.strptime(dt_str, "%Y-%m-%dT%H:%M:%S")
    else:
        # å°è¯•è§£æå…¶ä»–æ ¼å¼
        detect_dt = datetime.fromisoformat(detect_time.replace('+08:00', ''))
    
    # è®¡ç®—èµ·å§‹æ—¶é—´
    start_dt = detect_dt - timedelta(minutes=time_window_minutes)
    
    # æ ¼å¼åŒ–æ—¶é—´èŒƒå›´
    start_time_str = start_dt.strftime("%Y-%m-%dT%H:%M:%S+08:00")
    end_time_str = detect_time  # ä½¿ç”¨ä¼ å…¥çš„åŸå§‹æ ¼å¼
    
    # æ„å»ºè¯·æ±‚æ¶ˆæ¯
    message_content = (
        f"Check if there are any application response slowdowns or latency anomalies "
        f"in the system, and analyze the causes. "
        f"({start_time_str} -- {end_time_str})"
    )
    
    payload = {
        "threadId": thread_id,
        "runId": run_id,
        "messages": [
            {
                "role": "user",
                "content": message_content,
                "id": f"msg_{int(time.time() * 1000)}_{os.urandom(4).hex()}"
            }
        ],
        "state": {},
        "tools": [],
        "context": [],
        "forwardedProps": {}
    }
    
    headers = {
        "Accept": "text/event-stream",
        "Content-Type": "application/json"
    }
    
    try:
        if verbose:
            print(f"è°ƒç”¨SREChat API: {api_url}")
            print(f"æ—¶é—´èŒƒå›´: {start_time_str} -- {end_time_str}")
            print(f"æ—¶é—´çª—å£: {time_window_minutes}åˆ†é’Ÿ")
            print(f"æ¶ˆæ¯å†…å®¹: {message_content}")
        
        response = requests.post(
            api_url,
            headers=headers,
            json=payload,
            timeout=60,
            stream=True
        )
        response.raise_for_status()
        
        # å¤„ç†æµå¼å“åº”
        report_text = ""
        rca_results = []  # å­˜å‚¨Root Cause Analysisç»“æœ
        
        for line in response.iter_lines():
            if line:
                line_text = line.decode('utf-8')
                # SSEæ ¼å¼é€šå¸¸æ˜¯ "data: {...}"
                if line_text.startswith("data: "):
                    data_text = line_text[6:]  # ç§»é™¤ "data: " å‰ç¼€
                    try:
                        data = json.loads(data_text)
                        
                        # ä¸“é—¨æå–Root Cause Analysisç»“æœ
                        if isinstance(data, dict):
                            # æ£€æŸ¥æ˜¯å¦æ˜¯Root Cause Analysisç»“æœ
                            if (data.get('type') == 'CUSTOM' and 
                                data.get('name') == 'AgentToolDisplay'):
                                
                                value = data.get('value', {})
                                if value.get('title') == 'Root Cause Analysis Result':
                                    content = value.get('content', {})
                                    fields = content.get('fields', [])
                                    
                                    # æå–summaryå’Œreport
                                    for field in fields:
                                        if field.get('key') == 'summary':
                                            rca_results.append({
                                                'type': 'summary',
                                                'content': field.get('children', '')
                                            })
                                        elif field.get('key') == 'report':
                                            rca_results.append({
                                                'type': 'report',
                                                'content': field.get('children', '')
                                            })
                            
                            # ä¿ç•™æ‰€æœ‰æ•°æ®ç”¨äºå¤‡ç”¨è§£æ
                            for key in ["content", "message", "text", "report", "data"]:
                                if key in data:
                                    report_text += str(data[key])
                        else:
                            report_text += data_text
                    except json.JSONDecodeError:
                        report_text += data_text
                else:
                    report_text += line_text
                report_text += "\n"
        
        # å¦‚æœæ‰¾åˆ°äº†RCAç»“æœï¼Œä¼˜å…ˆä½¿ç”¨
        if rca_results:
            formatted_report = "=== Root Cause Analysis ===\n\n"
            for result in rca_results:
                if result['type'] == 'summary':
                    formatted_report += "SUMMARY:\n" + result['content'] + "\n\n"
                elif result['type'] == 'report':
                    formatted_report += "DETAILED REPORT:\n" + result['content'] + "\n\n"
            report_text = formatted_report + "\n\n=== Original Response ===\n" + report_text
            if verbose:
                print("âœ… æ‰¾åˆ°RCAç»“æœï¼Œæ•°é‡:", len(rca_results))
        else:
            if verbose:
                print("âš ï¸  æœªæ‰¾åˆ°RCAç»“æœï¼Œä½¿ç”¨åŸå§‹å“åº”")
                print(f"åŸå§‹å“åº”é•¿åº¦: {len(report_text)} å­—ç¬¦")
                print(f"åŸå§‹å“åº”å‰200å­—ç¬¦: {report_text[:200]}")

        
        if not report_text.strip():
            report_text = "æœªèƒ½è·å–åˆ°æœ‰æ•ˆçš„æŠ¥å‘Šå†…å®¹"
        
        return report_text.strip()
        
    except requests.exceptions.RequestException as e:
        print(f"APIè°ƒç”¨å¤±è´¥: {e}")
        return f"APIè°ƒç”¨å¤±è´¥: {str(e)}"


def srechat_rca(
    data=None,
    inject_time: str = None,
    dataset: str = None,
    detect_time: str = None,
    api_url: str = None,
    time_window_minutes: int = 15,
    deepseek_api_key: str = None,
    llm_api_key: str = None,
    llm_model_name: str = None,
    llm_base_url: str = None,
    verbose: bool = False,
    **kwargs
) -> Dict[str, Any]:
    """
    SREChat RCAç®—æ³•
    
    è¿™ä¸ªç®—æ³•ä¸éœ€è¦dataå‚æ•°ï¼Œåªéœ€è¦æ£€æµ‹æ—¶é—´ï¼Œä¼šè‡ªåŠ¨è°ƒç”¨è¿œç¨‹APIè·å–æ ¹å› æŠ¥å‘Šï¼Œ
    ç„¶åä½¿ç”¨å¤§æ¨¡å‹è§£ææŠ¥å‘Šè·å–top5æ ¹å› ã€‚
    
    Args:
        data: æ•°æ®ï¼ˆæ­¤ç®—æ³•ä¸ä½¿ç”¨ï¼‰
        inject_time: æ³¨å…¥æ—¶é—´ï¼ˆå…¼å®¹æ€§å‚æ•°ï¼‰
        dataset: æ•°æ®é›†åç§°ï¼ˆå…¼å®¹æ€§å‚æ•°ï¼‰
        detect_time: æ£€æµ‹æ—¶é—´ï¼Œæ ¼å¼å¦‚ "2025-09-23T17:20:42+08:00"
                    å¦‚æœæœªæä¾›ï¼Œå°†ä½¿ç”¨inject_timeæˆ–å½“å‰æ—¶é—´
        api_url: SREChat APIåœ°å€ï¼Œé»˜è®¤ä¸º http://192.168.1.6:28522/api/v1/srechat
        time_window_minutes: æ£€æµ‹æ—¶é—´çª—å£ï¼ˆåˆ†é’Ÿï¼‰ï¼Œé»˜è®¤15åˆ†é’Ÿ
        deepseek_api_key: DeepSeek APIå¯†é’¥ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        llm_api_key: é€šç”¨LLM APIå¯†é’¥ï¼ˆæ¨èï¼‰
        llm_model_name: æ¨¡å‹åç§°ï¼Œå¦‚ 'qwen-plus', 'deepseek-chat'
        llm_base_url: APIåŸºç¡€URLï¼Œå¦‚ 'https://dashscope.aliyuncs.com/compatible-mode/v1'
        **kwargs: å…¶ä»–å‚æ•°
    
    Returns:
        å­—å…¸ï¼ŒåŒ…å« ranks å­—æ®µï¼ˆtop5æ ¹å› åˆ—è¡¨ï¼‰
    """
    # ç¡®å®šæ£€æµ‹æ—¶é—´
    if detect_time is None:
        if inject_time is not None:
            # å¦‚æœinject_timeæ˜¯æ—¶é—´æˆ³ï¼Œè½¬æ¢ä¸ºISOæ ¼å¼
            if isinstance(inject_time, (int, float)):
                from datetime import datetime
                dt = datetime.fromtimestamp(inject_time)
                detect_time = dt.strftime("%Y-%m-%dT%H:%M:%S+08:00")
            else:
                detect_time = str(inject_time)
        else:
            # ä½¿ç”¨å½“å‰æ—¶é—´
            from datetime import datetime
            detect_time = datetime.now().strftime("%Y-%m-%dT%H:%M:%S+08:00")
    
    # ç¡®å®šAPIåœ°å€
    if api_url is None:
        api_url = os.getenv("SRECHAT_API_URL", "http://120.26.30.82:31338/api/v1/srechat")
    
    # è°ƒç”¨SREChat APIè·å–æŠ¥å‘Š
    if verbose:
        print("æ­¥éª¤1: è°ƒç”¨SREChat APIè·å–æ ¹å› æŠ¥å‘Š...")
    report_text = call_srechat_api(
        detect_time=detect_time,
        api_url=api_url,
        time_window_minutes=time_window_minutes,
        verbose=verbose
    )

    if verbose:
        print(f"è·å–åˆ°æŠ¥å‘Šï¼Œé•¿åº¦: {len(report_text)} å­—ç¬¦")
        print("=" * 80)
        print("æŠ¥å‘Šå†…å®¹é¢„è§ˆ:")
        print(report_text[:500] if len(report_text) > 500 else report_text)
        print("=" * 80)
    
    # ä½¿ç”¨å¤§æ¨¡å‹è§£ææŠ¥å‘Š
    if verbose:
        print("\næ­¥éª¤2: ä½¿ç”¨å¤§æ¨¡å‹è§£ææŠ¥å‘Š...")
    
    # æ”¯æŒæ–°çš„å‚æ•°åæˆ–å…¼å®¹æ—§çš„å‚æ•°å
    llm_api_key = kwargs.get('llm_api_key') or deepseek_api_key
    llm_model_name = kwargs.get('llm_model_name')
    llm_base_url = kwargs.get('llm_base_url')
    
    root_causes = parse_report_with_llm(
        report_text=report_text,
        api_key=llm_api_key,
        model_name=llm_model_name,
        base_url=llm_base_url,
        verbose=verbose
    )
    
    if verbose:
        print(f"è§£æå‡º {len(root_causes)} ä¸ªæ ¹å› :")
        for i, rc in enumerate(root_causes, 1):
            print(f"  {i}. {rc}")

    # Convert to "service_reason" format to align with other algorithms in the project
    ranks_formatted = _format_service_reasons(root_causes, report_text)

    # Extract RCA content from the stream for user display/verification
    rca_info = _extract_rca_from_report(report_text)

    # LLM usage & simple matching with RCA services
    llm_used = bool(llm_api_key or os.getenv("LLM_API_KEY") or os.getenv("DEEPSEEK_API_KEY"))
    rca_services = set(rca_info.get("rca_services_from_table", []) or [])
    llm_services = set(root_causes or [])
    llm_match_count = len(rca_services.intersection(llm_services)) if rca_services else 0
    llm_match = llm_match_count > 0
    
    return {
        "ranks": ranks_formatted,
        "raw_ranks": root_causes,
        "report": report_text,
        "detect_time": detect_time,
        # Newly exposed RCA content and comparison
        "rca_summary": rca_info.get("rca_summary"),
        "rca_report_markdown": rca_info.get("rca_report_markdown"),
        "rca_services_from_table": rca_info.get("rca_services_from_table"),
        "llm_used": llm_used,
        "llm_match": llm_match,
        "llm_match_count": llm_match_count,
    }


# å¯¼å‡º
__all__ = ["srechat_rca"]

